This `data_readme.md` briefly documents the structure and use of data for the AI Hiring Simulation project. The repository aims to remain reproducible and organized, especially in the context of a simulated extension of the study proposed in the individual seminar paper on management and AI in labor markets.

The setup encourages a clean separation of code-generated data from externally sourced data. Only essential datasets that are not easily reproducible or are lightweight should be committed.

The directories are organized as follows:
- pulled: Contains raw data pulled from APIs, institutional databases (e.g., U.S. Department of Labor, Census Bureau). For example:
    - Unemployment Insurance wage records
    - Job seeker registration data
    - Vacancy records with SOC codes for matching to O\*NET
> [!NOTE]
> This folder is currently empty in this prototype but is relevant for a real-world replication based on U.S. administrative data, as outlined in the seminar paper.


- generated: This folder contains synthetic data generated by running the Python simulation code in the repo, including:
    - `simulated_outcomes.parquet`: Synthetic job seeker records with AI-based treatment, applications, match scores, retention outcomes, and simulated wages.
    - Additional experiment outputs (e.g., subgroup comparisons such as rural/urban groups) can be added here if saved programmatically.
    
The pulled and generated folders include a .gitignore file to prevent the accidental committing of generated data.